{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cyBERT: a flexible log parser based on the BERT language model\n",
    "\n",
    "## Table of Contents\n",
    "* Introduction\n",
    "* Generating Labeled Logs\n",
    "* Subword Tokenization\n",
    "* Data Loading\n",
    "* Fine-tuning pretrained BERT\n",
    "* Model Evaluation\n",
    "* Parsing with cyBERT\n",
    "\n",
    "## Introduction\n",
    "\n",
    "One of the most arduous tasks of any security operation (and equally as time consuming for a data scientist) is ETL and parsing. This notebook illustrates how to train a BERT language model using a toy dataset of just 1000 previously parsed apache server logs as a labeled data. We will fine-tune a pretrained BERT model from [HuggingFace](https://github.com/huggingface) with a classification layer for Named Entity Recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "import torch.nn.functional as F\n",
    "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
    "\n",
    "from tqdm import tqdm,trange\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import s3fs\n",
    "from os import path\n",
    "\n",
    "import cupy\n",
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Labels For Our Training Dataset\n",
    "\n",
    "To train our model we begin with a dataframe containing parsed logs and additional `raw` column containing the whole raw log as a string. We will use the column names as our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download log data\n",
    "APACHE_SAMPLE_CSV = \"apache_sample_1k.csv\"\n",
    "S3_BASE_PATH = \"rapidsai-data/cyber/clx\"\n",
    "\n",
    "if not path.exists(APACHE_SAMPLE_CSV):\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    fs.get(S3_BASE_PATH + \"/\" + APACHE_SAMPLE_CSV, APACHE_SAMPLE_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_df = cudf.read_csv(APACHE_SAMPLE_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_level</th>\n",
       "      <th>error_message</th>\n",
       "      <th>raw</th>\n",
       "      <th>remote_host</th>\n",
       "      <th>remote_logname</th>\n",
       "      <th>remote_user</th>\n",
       "      <th>request_header_referer</th>\n",
       "      <th>request_header_user_agent</th>\n",
       "      <th>request_header_user_agent__browser__family</th>\n",
       "      <th>request_header_user_agent__browser__version_string</th>\n",
       "      <th>...</th>\n",
       "      <th>request_url_username</th>\n",
       "      <th>response_bytes_clf</th>\n",
       "      <th>status</th>\n",
       "      <th>time_received</th>\n",
       "      <th>time_received_datetimeobj</th>\n",
       "      <th>time_received_isoformat</th>\n",
       "      <th>time_received_tz_datetimeobj</th>\n",
       "      <th>time_received_tz_isoformat</th>\n",
       "      <th>time_received_utc_datetimeobj</th>\n",
       "      <th>time_received_utc_isoformat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>188.21.191.74 - - [03/Sep/2016:08:10:04 +0200]...</td>\n",
       "      <td>188.21.191.74</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>http://www.almhuette-raith.at/</td>\n",
       "      <td>Mozilla/5.0 (iPad; CPU OS 9_3_5 like Mac OS X)...</td>\n",
       "      <td>Mobile Safari</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1457</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[03/Sep/2016:08:10:04 +0200]</td>\n",
       "      <td>1.472890e+12</td>\n",
       "      <td>2016-09-03T08:10:04</td>\n",
       "      <td>1.472883e+12</td>\n",
       "      <td>2016-09-03T08:10:04+02:00</td>\n",
       "      <td>1.472883e+12</td>\n",
       "      <td>2016-09-03T06:10:04+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    error_level error_message  \\\n",
       "128        <NA>          <NA>   \n",
       "\n",
       "                                                   raw    remote_host  \\\n",
       "128  188.21.191.74 - - [03/Sep/2016:08:10:04 +0200]...  188.21.191.74   \n",
       "\n",
       "    remote_logname remote_user          request_header_referer  \\\n",
       "128              -           -  http://www.almhuette-raith.at/   \n",
       "\n",
       "                             request_header_user_agent  \\\n",
       "128  Mozilla/5.0 (iPad; CPU OS 9_3_5 like Mac OS X)...   \n",
       "\n",
       "    request_header_user_agent__browser__family  \\\n",
       "128                              Mobile Safari   \n",
       "\n",
       "    request_header_user_agent__browser__version_string  ...  \\\n",
       "128                                                9.0  ...   \n",
       "\n",
       "     request_url_username response_bytes_clf status  \\\n",
       "128                  <NA>               1457  200.0   \n",
       "\n",
       "                    time_received time_received_datetimeobj  \\\n",
       "128  [03/Sep/2016:08:10:04 +0200]              1.472890e+12   \n",
       "\n",
       "     time_received_isoformat time_received_tz_datetimeobj  \\\n",
       "128      2016-09-03T08:10:04                 1.472883e+12   \n",
       "\n",
       "     time_received_tz_isoformat time_received_utc_datetimeobj  \\\n",
       "128   2016-09-03T08:10:04+02:00                  1.472883e+12   \n",
       "\n",
       "     time_received_utc_isoformat  \n",
       "128    2016-09-03T06:10:04+00:00  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample parsed log\n",
    "logs_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.108.213.19 - - [18/Jul/2018:21:53:07 +0200] \"GET / HTTP/1.1\" 200 10439 \"-\" \"Mozilla/5.0 (compatible; YandexBot/3.0; +http://yandex.com/bots)\" \"-\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample raw log\n",
    "print(logs_df.raw.loc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeler(index_no, cols):\n",
    "    \"\"\"\n",
    "    label the words in the raw log with the column name from the parsed log\n",
    "    \"\"\"\n",
    "    raw_split = logs_df.raw_preprocess[index_no].split()\n",
    "    \n",
    "    # words in raw but not in parsed logs labeled as 'other'\n",
    "    label_list = ['other'] * len(raw_split) \n",
    "    \n",
    "    # for each parsed column find the location of the sequence of words (sublist) in the raw log\n",
    "    for col in cols:\n",
    "        if str(logs_df[col][index_no]) not in {'','-','None','NaN'}:\n",
    "            sublist = str(logs_df[col][index_no]).split()\n",
    "            sublist_len=len(sublist)\n",
    "            match_count = 0\n",
    "            for ind in (i for i,el in enumerate(raw_split) if el==sublist[0]):\n",
    "                # words in raw log not present in the parsed log will be labeled with 'other'\n",
    "                if (match_count < 1) and (raw_split[ind:ind+sublist_len]==sublist) and (label_list[ind:ind+sublist_len] == ['other'] * sublist_len):\n",
    "                    label_list[ind:ind+sublist_len] = [col] * sublist_len\n",
    "                    match_count = 1\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_df['raw_preprocess'] = logs_df.raw.str.replace('\"','')\n",
    "\n",
    "# column names to use as lables\n",
    "cols = logs_df.columns.values.tolist()\n",
    "\n",
    "# do not use raw columns as labels\n",
    "cols.remove('raw')\n",
    "cols.remove('raw_preprocess')\n",
    "\n",
    "# using for loop for labeling funcition until string UDF capability in rapids- it is currently slow\n",
    "labels = []\n",
    "for indx in range(len(logs_df)):\n",
    "    labels.append(labeler(indx, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['remote_host', 'other', 'other', 'time_received', 'time_received', 'request_method', 'request_url', 'other', 'other', 'response_bytes_clf', 'other', 'request_header_user_agent', 'request_header_user_agent', 'request_header_user_agent', 'request_header_user_agent', 'other']\n"
     ]
    }
   ],
   "source": [
    "print(labels[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subword Labeling\n",
    "We are using the `bert-base-cased` tokenizer vocabulary. This tokenizer splits our whitespace separated words further into in dictionary sub-word pieces. The model eventually uses the label from the first piece of a word as the sole label for the word, so we do not care about the model's ability to predict individual labels for the sub-word pieces. For training, the label used for these pieces is `X`. To learn more see the [BERT paper](https://arxiv.org/abs/1810.04805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subword_labeler(log_list, label_list):\n",
    "    \"\"\"\n",
    "    label all subword pieces in tokenized log with an 'X'\n",
    "    \"\"\"\n",
    "    subword_labels = []\n",
    "    for log, tags in zip(log_list,label_list):\n",
    "        temp_tags = []\n",
    "        words = cudf.Series(log.split())\n",
    "        words_size = len(words)\n",
    "        subword_counts = words.str.subword_tokenize(\"resources/bert-base-cased-hash.txt\", 10000, 10000,\\\n",
    "                                                    max_rows_tensor=words_size,\\\n",
    "                                                    do_lower=False, do_truncate=False)[2].reshape(words_size, 3)[:,2]\n",
    "        for i, tag in enumerate(tags):\n",
    "            temp_tags.append(tag)\n",
    "            temp_tags.extend('X'* subword_counts[i].item())\n",
    "        subword_labels.append(temp_tags)\n",
    "    return subword_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subword_labels = subword_labeler(logs_df.raw_preprocess.to_arrow().to_pylist(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['remote_host', 'X', 'X', 'X', 'X', 'X', 'X', 'other', 'other', 'time_received', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'time_received', 'X', 'X', 'X', 'request_method', 'X', 'request_url', 'other', 'X', 'X', 'X', 'X', 'X', 'X', 'other', 'response_bytes_clf', 'X', 'other', 'request_header_user_agent', 'X', 'X', 'X', 'X', 'X', 'request_header_user_agent', 'X', 'X', 'request_header_user_agent', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'request_header_user_agent', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'other']\n"
     ]
    }
   ],
   "source": [
    "print(subword_labels[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a set list of all labels from our dataset, add `X` for wordpiece tokens we will not have tags for and `[PAD]` for logs shorter than the length of the model's embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of labels\n",
    "label_values = list(set(x for l in labels for x in l))\n",
    "\n",
    "label_values[:0] = ['[PAD]']  \n",
    "label_values.append('X')\n",
    "\n",
    "# Set a dict for mapping id to tag name\n",
    "label2idx = {t: i for i, t in enumerate(label_values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, 'request_url': 1, 'error_message': 2, 'time_received': 3, 'remote_host': 4, 'response_bytes_clf': 5, 'error_level': 6, 'request_header_user_agent': 7, 'request_method': 8, 'other': 9, 'request_header_referer': 10, 'X': 11}\n"
     ]
    }
   ],
   "source": [
    "print(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(l, content, width):\n",
    "    l.extend([content] * (width - len(l)))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_labels = [pad(x[:256], '[PAD]', 256) for x in subword_labels]\n",
    "int_labels = [[label2idx.get(l) for l in lab] for lab in padded_labels]\n",
    "label_tensor = torch.tensor(int_labels).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Datasets\n",
    "For training and validation our datasets need three features. (1) `input_ids` subword tokens as integers padded to the specific length of the model (2) `attention_mask` a binary mask that allows the model to ignore padding (3) `labels` corresponding labels for tokens as integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_cased_tokenizer(strings):\n",
    "    \"\"\"\n",
    "    converts cudf.Seires of strings to two torch tensors- token ids and attention mask with padding\n",
    "    \"\"\"    \n",
    "    num_strings = len(strings)\n",
    "    num_bytes = strings.str.byte_count().sum()\n",
    "    token_ids, mask = strings.str.subword_tokenize(\"resources/bert-base-cased-hash.txt\", 256, 256,\n",
    "                                                            max_rows_tensor=num_strings,\n",
    "                                                            do_lower=False, do_truncate=True)[:2]\n",
    "    # convert from cupy to torch tensor using dlpack\n",
    "    input_ids = from_dlpack(token_ids.reshape(num_strings,256).astype(cupy.float).toDlpack())\n",
    "    attention_mask = from_dlpack(mask.reshape(num_strings,256).astype(cupy.float).toDlpack())\n",
    "    return input_ids.type(torch.long), attention_mask.type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_masks = bert_cased_tokenizer(logs_df.raw_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "dataset = TensorDataset(input_ids, attention_masks, label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pytorch random_split to create training and validation data subsets\n",
    "dataset_size = len(input_ids)\n",
    "training_dataset, validation_dataset = random_split(dataset, (int(dataset_size*.8), int(dataset_size*.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "train_dataloader = DataLoader(dataset=training_dataset, shuffle=True, batch_size=32)\n",
    "val_dataloader = DataLoader(dataset=validation_dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning pretrained BERT\n",
    "Download pretrained model from HuggingFace and move to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(label2idx))\n",
    "\n",
    "# model to gpu\n",
    "model.cuda()\n",
    "# use multi-gpu if available\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimizer and learning rate for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    #fine tune all layer parameters\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    # only fine tune classifier parameters\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:12<00:12, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5919565171003341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:24<00:00, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03336314842104912\n",
      "CPU times: user 24.5 s, sys: 76.1 ms, total: 24.6 s\n",
      "Wall time: 24.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# using 2 epochs to avoid overfitting\n",
    "\n",
    "epochs = 2\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)[0]\n",
    "        # backward pass\n",
    "        loss.sum().backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.sum().item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no dropout or batch norm during eval\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.993115\n",
      "Accuracy score: 0.997868\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                       _     0.0000    0.0000    0.0000         0\n",
      "              emote_host     1.0000    1.0000    1.0000       176\n",
      "   equest_header_referer     1.0000    1.0000    1.0000        92\n",
      "equest_header_user_agent     0.9880    0.9940    0.9910       166\n",
      "           equest_method     1.0000    1.0000    1.0000       176\n",
      "              equest_url     0.9617    1.0000    0.9805       176\n",
      "       esponse_bytes_clf     1.0000    1.0000    1.0000       175\n",
      "            ime_received     1.0000    1.0000    1.0000       200\n",
      "              rror_level     1.0000    1.0000    1.0000        24\n",
      "            rror_message     0.7083    0.7083    0.7083        24\n",
      "                    ther     1.0000    1.0000    1.0000       602\n",
      "\n",
      "               micro avg     0.9907    0.9956    0.9931      1811\n",
      "               macro avg     0.8780    0.8820    0.8800      1811\n",
      "            weighted avg     0.9913    0.9956    0.9934      1811\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: remote_host seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: other seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: time_received seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: request_method seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: request_url seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: response_bytes_clf seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: request_header_user_agent seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: request_header_referer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: error_level seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: error_message seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Mapping index to name\n",
    "idx2label={label2idx[key] : key for key in label2idx.keys()}\n",
    "\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for step, batch in enumerate(val_dataloader):\n",
    "    input_ids, input_mask, label_ids = batch\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=None,\n",
    "        attention_mask=input_mask,)\n",
    "        \n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0] \n",
    "        \n",
    "    # Get NER predicted result\n",
    "    logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    # Get NER true result\n",
    "    label_ids = label_ids.detach().cpu().numpy()\n",
    "    \n",
    "    # Only predict the groud truth, mask=0, will not calculate\n",
    "    input_mask = input_mask.detach().cpu().numpy()\n",
    "    \n",
    "    # Compare the valuable predict result\n",
    "    for i,mask in enumerate(input_mask):\n",
    "        # ground truth \n",
    "        temp_1 = []\n",
    "        # Prediction\n",
    "        temp_2 = []\n",
    "        \n",
    "        for j, m in enumerate(mask):\n",
    "            # Mask=0 is PAD, do not compare\n",
    "            if m: # Exclude the X label\n",
    "                if idx2label[label_ids[i][j]] != \"X\" and idx2label[label_ids[i][j]] != \"[PAD]\": \n",
    "                    temp_1.append(idx2label[label_ids[i][j]])\n",
    "                    temp_2.append(idx2label[logits[i][j]])\n",
    "            else:\n",
    "                break      \n",
    "        y_true.append(temp_1)\n",
    "        y_pred.append(temp_2)\n",
    "\n",
    "print(\"f1 score: %f\"%(f1_score(y_true, y_pred)))\n",
    "print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "# Get acc , recall, F1 result report\n",
    "print(classification_report(y_true, y_pred,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model files for future parsing with cyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model weights \n",
    "#torch.save(model.state_dict(), 'path/to/save.pth')\n",
    "\n",
    "# label map\n",
    "#with open('path/to/save.pth', mode=\"wt\") as output:\n",
    "#    for label in idx2label.values():\n",
    "#        output.writelines(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
